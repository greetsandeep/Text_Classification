{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import sklearn\n",
    "import unicodedata\n",
    "import math\n",
    "from nltk.tokenize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = sys.argv[1]\n",
    "OUTPUT_FILE = sys.argv[2]\n",
    "# 6 categories and 21 subcategories\n",
    "word_counts = {\"1\":{},\"2\":{},\"3\":{},\"4\":{},\"5\":{},\"6\":{}}\n",
    "vocab = {}\n",
    "category_prior = {\"1\":0.0,\"2\":0.0,\"3\":0.0,\"4\":0.0,\"5\":0.0,\"6\":0.0}\n",
    "subcategory_prior = {}\n",
    "row_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0}\n",
      "{'1': 0.0, '3': 0.0, '2': 0.0, '5': 0.0, '4': 0.0, '6': 0.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in xrange(22):\n",
    "    subcategory_prior[i] = 0.0\n",
    "print subcategory_prior\n",
    "print category_prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(words):\n",
    "    wc = {}\n",
    "    for word in words:\n",
    "        wc[word.encode(\"ascii\")] = wc.get(word.encode(\"ascii\"),0.0) + 1.0\n",
    "    \n",
    "    return wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> for training data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 4866.0, '3': 11.0, '2': 3921.0, '5': 4102.0, '4': 1389.0, '6': 5712.0}\n"
     ]
    }
   ],
   "source": [
    "tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "with open('feature_svm_train.csv','rb') as readfile:\n",
    "    with open(OUTPUT_FILE,'w') as writefile:\n",
    "        \n",
    "        reader = csv.reader(readfile, skipinitialspace =False, quoting=csv.QUOTE_MINIMAL)\n",
    "        writer = csv.writer(writefile, quoting = csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        for row in reader:\n",
    "            if row_num<=20000:\n",
    "                x = tknzr.tokenize(row[0])\n",
    "                for words in x:\n",
    "                    words.encode(\"ascii\",\"ignore\")\n",
    "                category_prior[row[1]] += 1\n",
    "                subcategory_prior[int(row[2])] +=1\n",
    "                counts = count_words(x)\n",
    "                \n",
    "                #print counts\n",
    "                for word, count in list(counts.items()):\n",
    "                    if word not in vocab:\n",
    "                        vocab[word] = 0.0\n",
    "                    if word not in word_counts[row[1]]:\n",
    "                        word_counts[row[1]][word] = 0.0\n",
    "                    vocab[word] = vocab[word] + count\n",
    "                    word_counts[row[1]][word]+=count\n",
    "                row_num += 1\n",
    "            else:\n",
    "                break\n",
    "        print category_prior\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2> For samples </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0020405904236631485, 0.0022410653995614542, 0.0, 0.0012316663943594706, 0.0013035182856671245, 0.0006741740765620974]\n",
      "[0.0005452239505157761, 0.0, 6.773826477653205e-07, 9.052481869864687e-05]\n",
      "[0.0020405904236631485, 0.0022410653995614542, 0.0, 0.0012316663943594706, 0.0013035182856671245, 0.0006741740765620974, 9.866062189880789e-05, 3.808346430627308e-05, 0.0, 0.00023879246421255044, 8.495929236191687e-05, 3.9728115225980744e-05]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'7'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-15da9f78d5df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mprob_word_given_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_word_given_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mprob_label_given_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_word_given_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcategory_prior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_prior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mprob_label_given_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '7'"
     ]
    }
   ],
   "source": [
    "with open('feature_svm_test.csv') as examplefile:\n",
    "    reader = csv.reader(examplefile, skipinitialspace =False, quoting=csv.QUOTE_MINIMAL)\n",
    "    list_item = 1\n",
    "    correct = 0\n",
    "    prob_word_given_label =[]\n",
    "    prob_label_given_word = []\n",
    "    for row in reader:\n",
    "        x = tknzr.tokenize(row[0])\n",
    "        for words in x:\n",
    "            words.encode(\"ascii\",\"ignore\")\n",
    "            \n",
    "        counts = count_words(x)\n",
    "        \n",
    "        category_classification = {\"1\":0.0,\"2\":0.0,\"3\":0.0,\"4\":0.0,\"5\":0.0,\"6\":0.0}\n",
    "        for word, count in list(counts.items()):\n",
    "            if word not in vocab:\n",
    "                continue\n",
    "            for i in range(1,len(list(word_counts.values()))+1):\n",
    "                prob_word_given_label.append(word_counts[str(i)].get(word,0.0)/sum(word_counts[str(i)].values()))\n",
    "            print prob_word_given_label\n",
    "            for i in range(1,len(prob_word_given_label)):\n",
    "                prob_label_given_word.append(prob_word_given_label[i] * category_prior[str(i)]/sum(category_prior.values()))\n",
    "            print prob_label_given_word\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
